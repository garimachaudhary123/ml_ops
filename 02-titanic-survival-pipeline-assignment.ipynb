{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Survival on the Titanic\n",
    "\n",
    "### History\n",
    "Perhaps one of the most infamous shipwrecks in history, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 people on board. Interestingly, by analysing the probability of survival based on few attributes like gender, age, and social status, we can make very accurate predictions on which passengers would survive. Some groups of people were more likely to survive than others, such as women, children, and the upper-class. Therefore, we can learn about the society priorities and privileges at the time.\n",
    "\n",
    "### Assignment:\n",
    "\n",
    "Build a Machine Learning Pipeline, to engineer the features in the data set and predict who is more likely to Survive the catastrophe.\n",
    "\n",
    "Follow the Jupyter notebook below, and complete the missing bits of code, to achieve each one of the pipeline steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting feature_engine\n",
      "  Using cached https://files.pythonhosted.org/packages/58/a6/b5572f9e50b9ce3db8548633d4b38808110900e78f6152c31214131356b8/feature_engine-1.4.0-py2.py3-none-any.whl\n",
      "Collecting pandas>=1.0.3 (from feature_engine)\n",
      "  Using cached https://files.pythonhosted.org/packages/99/f0/f99700ef327e51d291efdf4a6de29e685c4d198cbf8531541fc84d169e0e/pandas-1.3.5.tar.gz\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting scipy>=1.4.1 (from feature_engine)\n",
      "  Using cached https://files.pythonhosted.org/packages/58/4f/11f34cfc57ead25752a7992b069c36f5d18421958ebd6466ecd849aeaf86/scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n",
      "Collecting numpy>=1.18.2 (from feature_engine)\n",
      "  Using cached https://files.pythonhosted.org/packages/6d/ad/ff3b21ebfe79a4d25b4a4f8e5cf9fd44a204adb6b33c09010f566f51027a/numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n",
      "Collecting statsmodels>=0.11.1 (from feature_engine)\n",
      "  Using cached https://files.pythonhosted.org/packages/a4/7d/a919dbad04ec31741eee6a7f7df4a9a9e57e3b863900e48b079a6b832aab/statsmodels-0.13.5.tar.gz\n",
      "  Installing build dependencies ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /opt/conda/bin/python /opt/conda/lib/python3.7/site-packages/pip install --ignore-installed --no-user --prefix /tmp/pip-build-env-7p2njx60/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- 'setuptools>=59.2.0' 'wheel>=0.37.1' 'cython>=0.29.32,<3' 'oldest-supported-numpy; python_version!='\"'\"'3.10'\"'\"' or platform_system!='\"'\"'Windows'\"'\"' or platform_python_implementation=='\"'\"'PyPy'\"'\"'' 'numpy==1.22.3; python_version=='\"'\"'3.10'\"'\"' and platform_system=='\"'\"'Windows'\"'\"' and platform_python_implementation != '\"'\"'PyPy'\"'\"'' 'numpy; python_version>='\"'\"'3.11'\"'\"'' 'scipy>=1.3,<1.8; python_version=='\"'\"'3.7'\"'\"'' 'scipy>=1.3,<1.9; python_version=='\"'\"'3.8'\"'\"' and platform_system=='\"'\"'Windows'\"'\"' and platform_machine=='\"'\"'x86'\"'\"'' 'scipy>=1.3,<1.9; python_version=='\"'\"'3.9'\"'\"' and platform_system=='\"'\"'Windows'\"'\"' and platform_machine=='\"'\"'x86'\"'\"'' 'scipy>=1.3,<1.10; (python_version>'\"'\"'3.9'\"'\"' or platform_system!='\"'\"'Windows'\"'\"' or platform_machine!='\"'\"'x86'\"'\"') and python_version<'\"'\"'3.12'\"'\"'' 'scipy>=1.9; python_version>='\"'\"'3.12'\"'\"'' 'setuptools_scm[toml]>=7.0,<8'\n",
      "       cwd: None\n",
      "  Complete output (5 lines):\n",
      "  Ignoring numpy: markers 'python_version == \"3.10\" and platform_system == \"Windows\" and platform_python_implementation != \"PyPy\"' don't match your environment\n",
      "  Ignoring numpy: markers 'python_version >= \"3.11\"' don't match your environment\n",
      "  Ignoring scipy: markers 'python_version == \"3.8\" and platform_system == \"Windows\" and platform_machine == \"x86\"' don't match your environment\n",
      "  Ignoring scipy: markers 'python_version == \"3.9\" and platform_system == \"Windows\" and platform_machine == \"x86\"' don't match your environment\n",
      "  ERROR: Double requirement given: scipy<1.10,>=1.3 (already in scipy<1.8,>=1.3, name='scipy')\n",
      "  ----------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install feature_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# to handle datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# to divide train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# to build the models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# to evaluate the models\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# to persist the model and the scaler\n",
    "import joblib\n",
    "\n",
    "# ========== NEW IMPORTS ========\n",
    "# Respect to notebook 02-Predicting-Survival-Titanic-Solution\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# for the preprocessors\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# for imputation\n",
    "\n",
    "from feature_engine.imputation import (\n",
    "    CategoricalImputer,\n",
    "    AddMissingIndicator,\n",
    "    MeanMedianImputer)\n",
    "\n",
    "# for encoding categorical variables\n",
    "from feature_engine.encoding import (\n",
    "    RareLabelEncoder,\n",
    "    OneHotEncoder\n",
    ")\n",
    "# for encoding categorical variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data - it is available open source and online\n",
    "\n",
    "data = pd.read_csv('phpMYEkMl.csv')\n",
    "\n",
    "# display data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace interrogation marks by NaN values\n",
    "\n",
    "data = data.replace('?', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retain only the first cabin if more than\n",
    "# 1 are available per passenger\n",
    "\n",
    "def get_first_cabin(row):\n",
    "    try:\n",
    "        return row.split()[0]\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "data['cabin'] = data['cabin'].apply(get_first_cabin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracts the title (Mr, Ms, etc) from the name variable\n",
    "\n",
    "def get_title(passenger):\n",
    "    line = passenger\n",
    "    if re.search('Mrs', line):\n",
    "        return 'Mrs'\n",
    "    elif re.search('Mr', line):\n",
    "        return 'Mr'\n",
    "    elif re.search('Miss', line):\n",
    "        return 'Miss'\n",
    "    elif re.search('Master', line):\n",
    "        return 'Master'\n",
    "    else:\n",
    "        return 'Other'\n",
    "    \n",
    "data['title'] = data['name'].apply(get_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast numerical variables as floats\n",
    "\n",
    "data['fare'] = data['fare'].astype('float')\n",
    "data['age'] = data['age'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary variables\n",
    "\n",
    "data.drop(labels=['name','ticket', 'boat', 'body','home.dest'], axis=1, inplace=True)\n",
    "\n",
    "# display data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the data set\n",
    "\n",
    "# data.to_csv('titanic.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin Assignment\n",
    "\n",
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of variables to be used in the pipeline's transformers\n",
    "\n",
    "NUMERICAL_VARIABLES = ['age','fare']\n",
    "\n",
    "CATEGORICAL_VARIABLES = ['sex','cabin','embarked','title']\n",
    "\n",
    "CABIN = ['cabin']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop('survived', axis=1),  # predictors\n",
    "    data['survived'],  # target\n",
    "    test_size=0.2,  # percentage of obs in test set\n",
    "    random_state=0)  # seed to ensure reproducibility\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessors\n",
    "\n",
    "### Class to extract the letter from the variable Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractLetterTransformer():\n",
    "    # Extract first letter of variable\n",
    "\n",
    "    def __init__(self, variable):\n",
    "        self.variable = variable\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "       \n",
    "        X_copy = X.copy()\n",
    "        X_copy[self.variable] = X_copy[self.variable].str[0]\n",
    "        return X_copy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "- Impute categorical variables with string missing\n",
    "- Add a binary missing indicator to numerical variables with missing data\n",
    "- Fill NA in original numerical variable with the median\n",
    "- Extract first letter from cabin\n",
    "- Group rare Categories\n",
    "- Perform One hot encoding\n",
    "- Scale features with standard scaler\n",
    "- Fit a Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the pipeline\n",
    "titanic_pipe = Pipeline([\n",
    "\n",
    "    # ===== IMPUTATION =====\n",
    "    # impute categorical variables with string 'missing'\n",
    "    ('categorical_imputation', CategoricalImputer(imputation_method='missing', variables=CATEGORICAL_VARIABLES)),\n",
    "\n",
    "    # add missing indicator to numerical variables\n",
    "    ('missing_indicator',AddMissingIndicator(variables=NUMERICAL_VARIABLES) ),\n",
    "\n",
    "    # impute numerical variables with the median\n",
    "    ('median_imputation',MeanMedianImputer(imputation_method='median', variables=NUMERICAL_VARIABLES) ),\n",
    "\n",
    "\n",
    "    # Extract first letter from cabin\n",
    "    ('extract_letter', ExtractLetterTransformer(variables=CABIN)),\n",
    "\n",
    "\n",
    "    # == CATEGORICAL ENCODING ======\n",
    "    # remove categories present in less than 5% of the observations (0.05)\n",
    "    # group them in one category called 'Rare'\n",
    "    ('rare_label_encoder',RareLabelEncoder(tol=0.05, n_categories=1, variables=CATEGORICAL_VARIABLES) ),\n",
    "\n",
    "\n",
    "    # encode categorical variables using one hot encoding into k-1 variables\n",
    "    #('categorical_encoder',OneHotEncoder(drop_last=True, variables=CATEGORICAL_VARIABLES)  ),\n",
    "\n",
    "    # scale using standardization\n",
    "    ('scaler',StandardScaler()  ),\n",
    "\n",
    "    # logistic regression (use C=0.0005 and random_state=0)\n",
    "    ('Logit',LogisticRegression(C=0.0005, random_state=0) ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the pipeline\n",
    "\n",
    "titanic_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions and evaluate model performance\n",
    "\n",
    "Determine:\n",
    "- roc-auc\n",
    "- accuracy\n",
    "\n",
    "**Important, remember that to determine the accuracy, you need the outcome 0, 1, referring to survived or not. But to determine the roc-auc you need the probability of survival.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for train set\n",
    "class_ =  titanic_pipe.predict(X_train)\n",
    "pred = titanic_pipe.predict_proba(X_train)[:,1]\n",
    "\n",
    "# determine mse and rmse\n",
    "print('train roc-auc: {}'.format(roc_auc_score(y_train, pred)))\n",
    "print('train accuracy: {}'.format(accuracy_score(y_train, class_)))\n",
    "print()\n",
    "\n",
    "# make predictions for test set\n",
    "class_ = titanic_pipe.predict(X_test)\n",
    "pred = titanic_pipe.predict_proba(X_test)[:,1]\n",
    "\n",
    "# determine mse and rmse\n",
    "print('test roc-auc: {}'.format(roc_auc_score(y_test, pred)))\n",
    "print('test accuracy: {}'.format(accuracy_score(y_test, class_)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! Well done\n",
    "\n",
    "**Keep this code safe, as we will use this notebook later on, to build production code, in our next assignement!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
